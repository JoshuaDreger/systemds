#
# DESCRIPTION:
# ------------------------------------------------------------
# This script optimizes the parameters for an hmm model given Observation Sequences
# It does this by maximizing the Likelihood of the Observation Sequences occuring.
# It therefore uses the Baum Welch Algorithm.
# Basing on an Expectation Maximization strategy the Algorithm updates the hmm model parameters iteratively.
# ------------------------------------------------------------------------------------------
#
# INPUT:
# --------------------------------------------------------------------------------------------
# observations_sequences    Observation Sequences to train the model on
# iterations_count          Number of Iterations the Probabilities should be updated
# start_prob                Start probabilities
# transition_prob           Transition probabilities
# emission_prob             Emission probabilities
# ----------------------------------------------------------------------------------------
#
# OUTPUT:
# --------------------------------------------------------------------------------------------
# start_prob                Optimized Start probabilities
# transition_prob           Optimized Transition probabilities
# emission_prob             Optimized Emission probabilities
# --------------------------------------------------------------------------------------------

m_hmm_fit = function(matrix[Double] observations_sequences, Integer iterations_count,
                     matrix[Double] start_prob, matrix[Double] transition_prob,
                     matrix[Double] emission_prob)
    return(matrix[Double] start_prob, matrix[Double] transition_prob,
           matrix[Double] emission_prob)
    {
        sequence_length = ncol(observations_sequences)
        for i in range of iterations_count:
            # Expectation Step (Expected Transitions and Emissions)
            forward_prob = forward(observations_sequences, start_prob, transition_prob, emission_prob)
            backward_prob = backward(observations_sequences, transition_prob, emission_prob)
            observation_prob = sum(forward_prob[,sequence_length])






    }


# TODO: Save probabilities of forward_prob as log to achieve numerical stability
# Until numerical stability is achieved max sequence_length is bounded by 382 with evenly distibuted trans_prob & emission_prob and observation_count = 7, hiddenstates_count = 4
# Double Precision: 2.0E-323
forward = function(matrix[Double] observations_sequences, matrix[Double] start_prob, 
                   matrix[Double] transition_prob, matrix[Double] emission_prob)
    return(matrix[double] forward_prob)
    {   
        hiddenstates_count = ncol(transition_prob)
        observations_count = ncol(observations_sequences)
        forward_prob = matrix(0, rows = hiddenstates_count, cols = observations_count)

        observation = as.scalar(observations_sequences[1,1])
        forward_prob[,1] = start_prob * emission_prob[,observation] #Outer vector product

        for (k in 2:observations_count) {
            observation = as.scalar(observations_sequences[1,k])
            forward_prob[,k] = (transition_prob %*% forward_prob[,k-1]) * emission_prob[,observation]
        }
    }

# TODO: Save probabilities of forward_prob as log to achieve numerical stability
backward = function(matrix[Double] observations_sequences, matrix[Double] transition_prob, 
                    matrix[Double] emission_prob)
    return(matrix[double] backward_prob)
    {   
        hiddenstates_count = ncol(transition_prob)
        observations_count = ncol(observations_sequences)
        backward_prob = matrix(0, rows = hiddenstates_count, cols = observations_count)

        backward_prob[,observations_count] = matrix(1,rows = hiddenstates_count, cols = 1)

        for (k in (observations_count-1):1) {
            observation = as.scalar(observations_sequences[1,k])
            backward_prob[,k] = (transition_prob %*% backward_prob[,k+1]) * emission_prob[,observation]
        }
    }